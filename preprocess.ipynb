{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps ##\n",
    "\n",
    "#### Data Cleaning\n",
    "* Remove punctuations from `review_text`\n",
    "* Lowercase all text\n",
    "* **Remove samples with repetitive user IDs**\n",
    "* **Remove 'b' in front of each piece of review text**\n",
    "\n",
    "#### Match review text with location\n",
    "* For each piece of review text in `yelp_review_cleaned.csv`, we extract `business_id` to match it with `city` and `state` from the business data \n",
    "* Costruct a new csv file with columns `business_id`, `text`, `city`, `state`\n",
    "* **Remove foreign states (e.g. Vancouver)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'lWC-xP3rd6obsecCYsGZRg'</td>\n",
       "      <td>3</td>\n",
       "      <td>b\"Apparently Prides Osteria had a rough summer...</td>\n",
       "      <td>b'buF9druCkbuXLX526sGELQ'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'ak0TdVmGKo4pwqdJSTLwWw'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'2014-10-11 03:34:02'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'8bFej1QE5LXp4O05qjGqXA'</td>\n",
       "      <td>1</td>\n",
       "      <td>b'This store is pretty good. Not as great as W...</td>\n",
       "      <td>b'RA4V8pr014UyUbDvI-LW2A'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'YoVfDbnISlW0f7abNQACIg'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'2015-07-03 20:38:25'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'NDhkzczKjLshODbqDoNLSg'</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"I called WVM on the recommendation of a coup...</td>\n",
       "      <td>b'_sS2LBIGNT5NQb6PD1Vtjw'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'eC5evKn1TWDyHCyQAwguUw'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'2013-05-28 20:38:06'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'T5fAqjjFooT4V0OeZyuk1w'</td>\n",
       "      <td>1</td>\n",
       "      <td>b\"I've stayed at many Marriott and Renaissance...</td>\n",
       "      <td>b'0AzLzHfOJgL7ROwhdww2ew'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'SFQ1jcnGguO0LYWnbbftAA'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'2010-01-08 02:29:15'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'sjm_uUcQVxab_EeLCqsYLg'</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"The food is always great here. The service f...</td>\n",
       "      <td>b'8zehGz9jnxPqXtOc7KaJxA'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'0kA0PAJ8QFMeveQWHFqz2A'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'2011-07-28 18:05:01'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635398</th>\n",
       "      <td>b'PHnqMOU1pzHbnUMk3Cg2zA'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'In December, I called in (as a returning cus...</td>\n",
       "      <td>b'yyTtwwQ4JnQMJ2rn3W0S0g'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'6olZ0y9oW9azON61AhwxYg'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'2021-01-26 04:07:14'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635399</th>\n",
       "      <td>b'dViF8gg9745CszpekNvp2g'</td>\n",
       "      <td>13</td>\n",
       "      <td>b'This guy is a moron that will stalk and hara...</td>\n",
       "      <td>b'RDgwjgbu5xziFIAaNn3WCQ'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>b'EPYNZQFuSKqLi-on3U9dFg'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'2019-05-01 21:21:43'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635400</th>\n",
       "      <td>b'7vNXRIClt-9rFzMXlrtMXA'</td>\n",
       "      <td>39</td>\n",
       "      <td>b'Yummy, great chew on the bagel\\nFriendly sta...</td>\n",
       "      <td>b'rbuj2X4SXIc3MDul4dcxIA'</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>b'tr13Jb83h2itjyXVwaO5eA'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'2020-06-13 02:39:26'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635401</th>\n",
       "      <td>b'Ho57jz6U-JjrGHpGWIGLNg'</td>\n",
       "      <td>2</td>\n",
       "      <td>b\"This used to be my car wash of choice. They ...</td>\n",
       "      <td>b'IRzjEZ2pX4iOpnBG7oZJ7g'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b'HqdmRMpNvScFxjGAB40vgQ'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'2020-06-22 21:54:10'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635402</th>\n",
       "      <td>b'YNyurWy1ZIYEy1vXI7azOg'</td>\n",
       "      <td>11</td>\n",
       "      <td>b\"This is so highly rated for a reason. If you...</td>\n",
       "      <td>b'pxwYIa1jZzHJ4R0Sp1cHFw'</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>b'HsT8bz3-SKMk7YidwLLM6Q'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'2019-04-17 04:27:39'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8635403 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         review_id  useful  \\\n",
       "0        b'lWC-xP3rd6obsecCYsGZRg'       3   \n",
       "1        b'8bFej1QE5LXp4O05qjGqXA'       1   \n",
       "2        b'NDhkzczKjLshODbqDoNLSg'       0   \n",
       "3        b'T5fAqjjFooT4V0OeZyuk1w'       1   \n",
       "4        b'sjm_uUcQVxab_EeLCqsYLg'       0   \n",
       "...                            ...     ...   \n",
       "8635398  b'PHnqMOU1pzHbnUMk3Cg2zA'       0   \n",
       "8635399  b'dViF8gg9745CszpekNvp2g'      13   \n",
       "8635400  b'7vNXRIClt-9rFzMXlrtMXA'      39   \n",
       "8635401  b'Ho57jz6U-JjrGHpGWIGLNg'       2   \n",
       "8635402  b'YNyurWy1ZIYEy1vXI7azOg'      11   \n",
       "\n",
       "                                                      text  \\\n",
       "0        b\"Apparently Prides Osteria had a rough summer...   \n",
       "1        b'This store is pretty good. Not as great as W...   \n",
       "2        b\"I called WVM on the recommendation of a coup...   \n",
       "3        b\"I've stayed at many Marriott and Renaissance...   \n",
       "4        b\"The food is always great here. The service f...   \n",
       "...                                                    ...   \n",
       "8635398  b'In December, I called in (as a returning cus...   \n",
       "8635399  b'This guy is a moron that will stalk and hara...   \n",
       "8635400  b'Yummy, great chew on the bagel\\nFriendly sta...   \n",
       "8635401  b\"This used to be my car wash of choice. They ...   \n",
       "8635402  b\"This is so highly rated for a reason. If you...   \n",
       "\n",
       "                       business_id  cool  funny                    user_id  \\\n",
       "0        b'buF9druCkbuXLX526sGELQ'     1      1  b'ak0TdVmGKo4pwqdJSTLwWw'   \n",
       "1        b'RA4V8pr014UyUbDvI-LW2A'     0      0  b'YoVfDbnISlW0f7abNQACIg'   \n",
       "2        b'_sS2LBIGNT5NQb6PD1Vtjw'     0      0  b'eC5evKn1TWDyHCyQAwguUw'   \n",
       "3        b'0AzLzHfOJgL7ROwhdww2ew'     1      1  b'SFQ1jcnGguO0LYWnbbftAA'   \n",
       "4        b'8zehGz9jnxPqXtOc7KaJxA'     0      0  b'0kA0PAJ8QFMeveQWHFqz2A'   \n",
       "...                            ...   ...    ...                        ...   \n",
       "8635398  b'yyTtwwQ4JnQMJ2rn3W0S0g'     0      0  b'6olZ0y9oW9azON61AhwxYg'   \n",
       "8635399  b'RDgwjgbu5xziFIAaNn3WCQ'     0      1  b'EPYNZQFuSKqLi-on3U9dFg'   \n",
       "8635400  b'rbuj2X4SXIc3MDul4dcxIA'    34     13  b'tr13Jb83h2itjyXVwaO5eA'   \n",
       "8635401  b'IRzjEZ2pX4iOpnBG7oZJ7g'     0      0  b'HqdmRMpNvScFxjGAB40vgQ'   \n",
       "8635402  b'pxwYIa1jZzHJ4R0Sp1cHFw'     5      4  b'HsT8bz3-SKMk7YidwLLM6Q'   \n",
       "\n",
       "         stars                    date  \n",
       "0          4.0  b'2014-10-11 03:34:02'  \n",
       "1          4.0  b'2015-07-03 20:38:25'  \n",
       "2          5.0  b'2013-05-28 20:38:06'  \n",
       "3          2.0  b'2010-01-08 02:29:15'  \n",
       "4          4.0  b'2011-07-28 18:05:01'  \n",
       "...        ...                     ...  \n",
       "8635398    1.0  b'2021-01-26 04:07:14'  \n",
       "8635399    1.0  b'2019-05-01 21:21:43'  \n",
       "8635400    5.0  b'2020-06-13 02:39:26'  \n",
       "8635401    2.0  b'2020-06-22 21:54:10'  \n",
       "8635402    5.0  b'2019-04-17 04:27:39'  \n",
       "\n",
       "[8635403 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of user IDSs: 8635403\n",
      "Number of unique user IDs: 2189457\n",
      "Number of unique indices: 2189457\n"
     ]
    }
   ],
   "source": [
    "user_ids = np.array(all_data['user_id'])\n",
    "print(f'Total number of user IDSs: {user_ids.size}')\n",
    "unique_user_ids, unique_user_id_indices = np.unique(user_ids, return_index=True)\n",
    "print(f'Number of unique user IDs: {unique_user_ids.size}')\n",
    "print(f'Number of unique indices: {indices.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"b'---2PmXbF47D870stH1jqA'\", \"b'---7FS-3SMy-cnnIPHcW9w'\",\n",
       "       \"b'---fQxo-9tYZAkyWYrSfdA'\", ..., \"b'zzzcuxFaP_FvdIB-fbP9iA'\",\n",
       "       \"b'zzzl5-rnSu3jclcANGsLgg'\", \"b'zzzqnB-6DlYUbqAPxUxg4A'\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out samples with repetitive user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove punctuations\n",
    "    clean_text = [char for char in text if char not in string.punctuation]\n",
    "    clean_text = ''.join(clean_text)\n",
    "    # lower case all text\n",
    "    clean_text = clean_text.lower()\n",
    "    return clean_text\n",
    "\n",
    "clean_data_path = 'yelp_review_cleaned.csv'\n",
    "column_names = ['business_id', 'user_id', 'text']\n",
    "\n",
    "with open(clean_data_path, 'w') as csv_file:\n",
    "    csv_file = csv.writer(csv_file)\n",
    "    csv_file.writerow(column_names)\n",
    "    \n",
    "    for idx in unique_user_id_indices:\n",
    "        cleaned_text = clean_text(all_data['text'][idx][1:])\n",
    "        business_id = all_data['business_id'][idx].split(\"'\")[1]\n",
    "        user_id = all_data['user_id'][idx]\n",
    "        csv_file.writerow([business_id, user_id, cleaned_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y_c38tCm3aQps72zSGW4Lw</td>\n",
       "      <td>what a wonderful evening and what a gracious h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GzFD07Y8SbSF5ZPfhmR_ig</td>\n",
       "      <td>my first experience with these folks was downr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zu2MOe5SZtvJUzVJBhgvpw</td>\n",
       "      <td>this is by far my favorite cafxc3xa9 ever the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OLj0IIty__HPZjiefd1BkA</td>\n",
       "      <td>casual atmosphere  the service could be slow i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RRCLBnBD7c6HWBurhIHAXA</td>\n",
       "      <td>the food and ambiance was excellent during our...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text\n",
       "0  y_c38tCm3aQps72zSGW4Lw  what a wonderful evening and what a gracious h...\n",
       "1  GzFD07Y8SbSF5ZPfhmR_ig  my first experience with these folks was downr...\n",
       "2  zu2MOe5SZtvJUzVJBhgvpw  this is by far my favorite cafxc3xa9 ever the ...\n",
       "3  OLj0IIty__HPZjiefd1BkA  casual atmosphere  the service could be slow i...\n",
       "4  RRCLBnBD7c6HWBurhIHAXA  the food and ambiance was excellent during our..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_data_path = \"yelp_academic_dataset_business.csv\"\n",
    "clean_data_path = 'yelp_review_cleaned.csv'\n",
    "\n",
    "clean_text = pd.read_csv(clean_data_path)\n",
    "business_info = pd.read_csv(business_data_path)\n",
    "clean_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of states: 51\n",
      "['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('us_states.json') as json_file:\n",
    "    us_states = json.load(json_file)\n",
    "\n",
    "all_states = [state['Code'] for state in us_states]\n",
    "print(f'Total number of states: {len(all_states)}')\n",
    "print(all_states)\n",
    "'BC' in all_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import *\n",
    "\n",
    "ensemble_data_path = 'ensemble.csv'\n",
    "column_names = [\"city\", \"state\", \"text\"]\n",
    "\n",
    "text_business_ids = np.array(clean_text['business_id'])\n",
    "all_business_ids = np.array(business_info['business_id'])\n",
    "all_cities = np.array(business_info['city'])\n",
    "all_states = np.array(business_info['state'])\n",
    "    \n",
    "# write a new csv file with column names: city, state, text\n",
    "with open(ensemble_data_path, 'w') as csv_file:\n",
    "    csv_file = csv.writer(csv_file)\n",
    "    csv_file.writerow(column_names)\n",
    "    \n",
    "    for i in islice(count(), 0, len(text_business_ids)-1):\n",
    "        item_loc = np.where(all_business_ids == text_business_ids[i])[0][0]\n",
    "        state = all_states[item_loc]\n",
    "        if state in all_states and state != 'BC':\n",
    "            city = all_cities[item_loc]\n",
    "            review_text = clean_text['text'][item_loc]\n",
    "            csv_file.writerow([city, state, review_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ensemble_data_path = 'ensemble.csv'\n",
    "ensemble_data = pd.read_csv(ensemble_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smyrna</td>\n",
       "      <td>GA</td>\n",
       "      <td>been on the east coast for a month and this is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>it says on here and in the search results that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake Mary</td>\n",
       "      <td>FL</td>\n",
       "      <td>fantastic food atmosphere and service i had th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>great higher end mall loads of stores and some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>FL</td>\n",
       "      <td>i absolutely love this place the food was amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city state                                               text\n",
       "0     Smyrna    GA  been on the east coast for a month and this is...\n",
       "1     Boston    MA  it says on here and in the search results that...\n",
       "2  Lake Mary    FL  fantastic food atmosphere and service i had th...\n",
       "3     Austin    TX  great higher end mall loads of stores and some...\n",
       "4    Orlando    FL  i absolutely love this place the food was amaz..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my pup was due for his shots and while my vet didnt charge a lot for them he did charge 40 for a mandatory check up so i decided to try emancipet and give them a donationnyes there was a wait to see the vet but it was only in the neighborhood of 30 minutes when i got in the nurse is the right term was very pleasant seeing what i wanted  and taking care of business the vet was very pleasant also and yes there was a charge for her check up 5nthe only draw back was the wait to pay  im not sure whether the holdup was the doctor getting my chart to the bookkeeper or the bookkeeper but it was well over ten minutes and longer then it should have been on top of that someone who finished after i did was able to check out before me  never a pleasing eventnwhen i was able to check out i added a donation to the bill which i hate to admit would have been bigger if i had been checked out more efficientlynas for as im concerned emancipet is now my dogs vet and i will continue to use them and make a regular donation i love the idea that they enable people who may not otherwise be able afford a pet andor pet care have a place to go for their pets welfare'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_data['text'][1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = pd.read_csv('ensemble.csv')\n",
    "text = np.array(ensemble['text'])\n",
    "print(f'Total text: {text.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_review, unique_review_indices = np.unique(text, return_index=True)\n",
    "print(f'Number of unique reviews: {unique_review.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"city\", \"state\", \"text\"]\n",
    "\n",
    "with open('ensemble2.csv', 'w') as csv_file:\n",
    "    csv_file = csv.writer(csv_file)\n",
    "    csv_file.writerow(column_names)\n",
    "    \n",
    "    for idx in unique_review_indices:\n",
    "        csv_file.writerow([ensemble['city'][idx], ensemble['state'][idx], ensemble['text'][idx] ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
